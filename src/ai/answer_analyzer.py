"""
–ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –æ—Ç–≤–µ—Ç–æ–≤ –∫–∞–Ω–¥–∏–¥–∞—Ç–∞.
"""
import json
import logging
import os
from datetime import datetime
from json import JSONDecoder

from src.ai.client import chat_completion
from src.core.prompts.system import get_analysis_prompt

logger = logging.getLogger(__name__)

# –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è debug-–ª–æ–≥–æ–≤
DEBUG_LOG_DIR = "debug_logs"


def log_ai_response(prompt_type: str, response: str, success: bool) -> None:
    """
    –°–æ—Ö—Ä–∞–Ω–∏—Ç—å —Å—ã—Ä–æ–π –æ—Ç–≤–µ—Ç AI –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏.
    
    Args:
        prompt_type: –¢–∏–ø –ø—Ä–æ–º–ø—Ç–∞ (analysis, question, report)
        response: –°—ã—Ä–æ–π –æ—Ç–≤–µ—Ç –æ—Ç AI
        success: –£—Å–ø–µ—à–Ω–æ –ª–∏ —Ä–∞—Å–ø–∞—Ä—Å–∏–ª–∏
    """
    try:
        os.makedirs(DEBUG_LOG_DIR, exist_ok=True)
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S_%f")
        status = "ok" if success else "fail"
        filename = f"{DEBUG_LOG_DIR}/{timestamp}_{prompt_type}_{status}.txt"
        
        with open(filename, "w", encoding="utf-8") as f:
            f.write(response)
    except Exception as e:
        logger.warning(f"Failed to log AI response: {e}")


def robust_json_parse(text: str) -> dict:
    """
    –†–æ–±–∞—Å—Ç–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥ JSON –∏–∑ –æ—Ç–≤–µ—Ç–∞ AI.
    
    –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç:
    - JSON –≤ markdown –±–ª–æ–∫–∞—Ö (```json ... ```)
    - JSON —Å trailing text (–∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏ –ø–æ—Å–ª–µ JSON)
    - JSON —Å leading text (–ø–æ—è—Å–Ω–µ–Ω–∏—è –¥–æ JSON)
    
    Args:
        text: –°—ã—Ä–æ–π —Ç–µ–∫—Å—Ç –æ—Ç AI
        
    Returns:
        –†–∞—Å–ø–∞—Ä—Å–µ–Ω–Ω—ã–π —Å–ª–æ–≤–∞—Ä—å
        
    Raises:
        ValueError: –ï—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ –≤–∞–ª–∏–¥–Ω—ã–π JSON
    """
    if not text or not text.strip():
        raise ValueError("Empty response")
    
    text = text.strip()
    
    # –°—Ç—Ä–∞—Ç–µ–≥–∏—è 1: –£–±–∏—Ä–∞–µ–º markdown code blocks
    if "```" in text:
        import re
        # –ò—â–µ–º ```json ... ``` (–∂–∞–¥–Ω—ã–π –ø–æ–∏—Å–∫ –¥–æ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ ```)
        code_block_match = re.search(r'```(?:json)?\s*\n([\s\S]+?)\n```', text)
        if code_block_match:
            text = code_block_match.group(1).strip()
        else:
            # –ü–æ–ø—Ä–æ–±—É–µ–º –±–µ–∑ –ø–µ—Ä–µ–Ω–æ—Å–∞ —Å—Ç—Ä–æ–∫–∏
            code_block_match = re.search(r'```(?:json)?\s*([\s\S]+?)```', text)
            if code_block_match:
                text = code_block_match.group(1).strip()
    
    # –°—Ç—Ä–∞—Ç–µ–≥–∏—è 2: –ü—Ä—è–º–æ–π –ø–∞—Ä—Å–∏–Ω–≥ (–µ—Å–ª–∏ —É–∂–µ —á–∏—Å—Ç—ã–π JSON)
    try:
        result = json.loads(text)
        if isinstance(result, dict):
            return result
    except json.JSONDecodeError:
        pass
    
    # –°—Ç—Ä–∞—Ç–µ–≥–∏—è 3: JSONDecoder.raw_decode (–∏–≥–Ω–æ—Ä–∏—Ä—É–µ—Ç trailing data)
    try:
        decoder = JSONDecoder()
        # –ò—â–µ–º –Ω–∞—á–∞–ª–æ JSON –æ–±—ä–µ–∫—Ç–∞
        start_idx = text.find('{')
        if start_idx != -1:
            obj, end_idx = decoder.raw_decode(text, start_idx)
            if isinstance(obj, dict):
                return obj
    except json.JSONDecodeError:
        pass
    
    # –°—Ç—Ä–∞—Ç–µ–≥–∏—è 4: –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ JSON —Å —É—á—ë—Ç–æ–º –≤–ª–æ–∂–µ–Ω–Ω–æ—Å—Ç–∏
    brace_count = 0
    start_idx = None
    
    for i, char in enumerate(text):
        if char == '{':
            if brace_count == 0:
                start_idx = i
            brace_count += 1
        elif char == '}':
            brace_count -= 1
            if brace_count == 0 and start_idx is not None:
                try:
                    candidate = text[start_idx:i+1]
                    result = json.loads(candidate)
                    if isinstance(result, dict):
                        return result
                except json.JSONDecodeError:
                    # –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º –∏—Å–∫–∞—Ç—å –¥—Ä—É–≥–æ–π JSON
                    start_idx = None
                    continue
    
    # –ù–∏—á–µ–≥–æ –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª–æ
    raise ValueError(f"No valid JSON found in response: {text[:200]}...")


# –í—Å–µ 12 –º–µ—Ç—Ä–∏–∫
ALL_METRICS = [
    # Hard Skills
    "expertise",
    "methodology", 
    "tools_proficiency",
    # Soft Skills
    "articulation",
    "self_awareness",
    "conflict_handling",
    # Thinking
    "depth",
    "structure",
    "systems_thinking",
    "creativity",
    # Mindset
    "honesty",
    "growth_orientation",
]

# –í—Å–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã –ø–æ–≤–µ–¥–µ–Ω–∏—è
ALL_PATTERNS = ["rehearsed", "evasive", "overconfident", "defensive", "authentic"]

# –†—É—Å—Å–∫–∏–µ –Ω–∞–∑–≤–∞–Ω–∏—è –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤
PATTERN_NAMES_RU = {
    "rehearsed": "üé≠ –ó–∞—É—á–µ–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç",
    "evasive": "üåä –£–∫–ª–æ–Ω—á–∏–≤–æ—Å—Ç—å",
    "overconfident": "üí™ –°–∞–º–æ—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å",
    "defensive": "üõ°Ô∏è –ó–∞—â–∏—Ç–Ω–∞—è –ø–æ–∑–∏—Ü–∏—è",
    "authentic": "üíé –ê—É—Ç–µ–Ω—Ç–∏—á–Ω–æ—Å—Ç—å",
}

# –í–ª–∏—è–Ω–∏–µ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –Ω–∞ –º–µ—Ç—Ä–∏–∫–∏ (–∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∫–∏)
PATTERN_ADJUSTMENTS = {
    "rehearsed": {"honesty": -1, "self_awareness": -1},
    "evasive": {"honesty": -2, "depth": -1},
    "overconfident": {"self_awareness": -2, "growth_orientation": -1},
    "defensive": {"honesty": -1, "self_awareness": -1, "growth_orientation": -1},
    "authentic": {"honesty": +1, "self_awareness": +1},  # –ü–æ–∑–∏—Ç–∏–≤–Ω—ã–π –±–æ–Ω—É—Å
}

# –†—É—Å—Å–∫–∏–µ –Ω–∞–∑–≤–∞–Ω–∏—è –º–µ—Ç—Ä–∏–∫ –¥–ª—è –æ—Ç—á—ë—Ç–∞
METRIC_NAMES_RU = {
    # Hard Skills
    "expertise": "–≠–∫—Å–ø–µ—Ä—Ç–∏–∑–∞",
    "methodology": "–ú–µ—Ç–æ–¥–æ–ª–æ–≥–∏–∏",
    "tools_proficiency": "–ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã",
    # Soft Skills
    "articulation": "–Ø—Å–Ω–æ—Å—Ç—å —Ä–µ—á–∏",
    "self_awareness": "–°–∞–º–æ–æ—Å–æ–∑–Ω–∞–Ω–∏–µ",
    "conflict_handling": "–†–∞–±–æ—Ç–∞ —Å –∫–æ–Ω—Ñ–ª–∏–∫—Ç–∞–º–∏",
    # Thinking
    "depth": "–ì–ª—É–±–∏–Ω–∞ –∞–Ω–∞–ª–∏–∑–∞",
    "structure": "–°—Ç—Ä—É–∫—Ç—É—Ä–Ω–æ—Å—Ç—å",
    "systems_thinking": "–°–∏—Å—Ç–µ–º–Ω–æ–µ –º—ã—à–ª–µ–Ω–∏–µ",
    "creativity": "–ö—Ä–µ–∞—Ç–∏–≤–Ω–æ—Å—Ç—å",
    # Mindset
    "honesty": "–ß–µ—Å—Ç–Ω–æ—Å—Ç—å",
    "growth_orientation": "–û—Ä–∏–µ–Ω—Ç–∞—Ü–∏—è –Ω–∞ —Ä–æ—Å—Ç",
}

# –ì—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ –º–µ—Ç—Ä–∏–∫ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
METRIC_CATEGORIES = {
    "hard_skills": {
        "name": "üîß Hard Skills",
        "metrics": ["expertise", "methodology", "tools_proficiency"],
        "max_score": 30,
    },
    "soft_skills": {
        "name": "ü§ù Soft Skills", 
        "metrics": ["articulation", "self_awareness", "conflict_handling"],
        "max_score": 25,
    },
    "thinking": {
        "name": "üß† –ú—ã—à–ª–µ–Ω–∏–µ",
        "metrics": ["depth", "structure", "systems_thinking", "creativity"],
        "max_score": 25,
    },
    "mindset": {
        "name": "üí´ Mindset",
        "metrics": ["honesty", "growth_orientation"],
        "max_score": 20,
    },
}

# –î–µ—Ñ–æ–ª—Ç–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –Ω–∞ —Å–ª—É—á–∞–π –æ—à–∏–±–∫–∏
DEFAULT_ANALYSIS = {
    "scores": {metric: 5 for metric in ALL_METRICS},
    "patterns": {pattern: False for pattern in ALL_PATTERNS},
    "detected_patterns": [],
    "key_insights": ["–ê–Ω–∞–ª–∏–∑ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω"],
    "gaps": [],
    "red_flags": [],
    "hypothesis": "–¢—Ä–µ–±—É–µ—Ç—Å—è –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑",
}


async def analyze_answer(question: str, answer: str, role: str) -> dict:
    """
    –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –æ—Ç–≤–µ—Ç –∫–∞–Ω–¥–∏–¥–∞—Ç–∞.
    
    Args:
        question: –ó–∞–¥–∞–Ω–Ω—ã–π –≤–æ–ø—Ä–æ—Å
        answer: –û—Ç–≤–µ—Ç –∫–∞–Ω–¥–∏–¥–∞—Ç–∞
        role: –†–æ–ª—å (designer/product)
        
    Returns:
        –°–ª–æ–≤–∞—Ä—å —Å –æ—Ü–µ–Ω–∫–∞–º–∏ –∏ –∏–Ω—Å–∞–π—Ç–∞–º–∏
    """
    response = None
    
    try:
        messages = get_analysis_prompt(question, answer, role)
        
        response = await chat_completion(
            messages=messages,
            temperature=0.3,  # –ë–æ–ª–µ–µ –¥–µ—Ç–µ—Ä–º–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑
            max_tokens=1000,
        )
        
        # –†–æ–±–∞—Å—Ç–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥ JSON
        analysis = robust_json_parse(response)
        
        # –í–∞–ª–∏–¥–∞—Ü–∏—è —Å—Ç—Ä—É–∫—Ç—É—Ä—ã
        if "scores" not in analysis:
            raise ValueError("Missing 'scores' in analysis")
        
        # –í–∞–ª–∏–¥–∞—Ü–∏—è –∏ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –∑–Ω–∞—á–µ–Ω–∏–π (0-10) –¥–ª—è –≤—Å–µ—Ö 12 –º–µ—Ç—Ä–∏–∫
        for metric in ALL_METRICS:
            if metric not in analysis["scores"]:
                analysis["scores"][metric] = 5  # –î–µ—Ñ–æ–ª—Ç –µ—Å–ª–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç
            else:
                value = analysis["scores"][metric]
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–∏–ø –∏ –¥–∏–∞–ø–∞–∑–æ–Ω
                if not isinstance(value, (int, float)):
                    analysis["scores"][metric] = 5
                else:
                    # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–∏–∞–ø–∞–∑–æ–Ω 0-10
                    analysis["scores"][metric] = max(0, min(10, value))
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –¥—Ä—É–≥–∏—Ö –ø–æ–ª–µ–π
        if "key_insights" not in analysis:
            analysis["key_insights"] = []
        if "gaps" not in analysis:
            analysis["gaps"] = []
        if "red_flags" not in analysis:
            analysis["red_flags"] = []
        if "hypothesis" not in analysis:
            analysis["hypothesis"] = ""
        
        # === –û–ë–†–ê–ë–û–¢–ö–ê –ü–ê–¢–¢–ï–†–ù–û–í ===
        if "patterns" not in analysis:
            analysis["patterns"] = {p: False for p in ALL_PATTERNS}
        else:
            # –í–∞–ª–∏–¥–∞—Ü–∏—è –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤
            for pattern in ALL_PATTERNS:
                if pattern not in analysis["patterns"]:
                    analysis["patterns"][pattern] = False
                elif not isinstance(analysis["patterns"][pattern], bool):
                    analysis["patterns"][pattern] = False
        
        # –ü—Ä–∏–º–µ–Ω—è–µ–º –∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∫–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤
        detected_patterns = []
        for pattern, is_detected in analysis["patterns"].items():
            if is_detected and pattern in PATTERN_ADJUSTMENTS:
                detected_patterns.append(pattern)
                adjustments = PATTERN_ADJUSTMENTS[pattern]
                for metric, delta in adjustments.items():
                    if metric in analysis["scores"]:
                        new_value = analysis["scores"][metric] + delta
                        analysis["scores"][metric] = max(0, min(10, new_value))
        
        # –õ–æ–≥–∏—Ä—É–µ–º –Ω–∞–π–¥–µ–Ω–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã
        if detected_patterns:
            logger.info(f"Detected patterns: {detected_patterns}")
            analysis["detected_patterns"] = detected_patterns
        else:
            analysis["detected_patterns"] = []
        
        # –õ–æ–≥–∏—Ä—É–µ–º —É—Å–ø–µ—à–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥
        log_ai_response("analysis", response, success=True)
        
        return analysis
        
    except ValueError as e:
        logger.error(f"Failed to parse AI response: {e}")
        if response:
            log_ai_response("analysis", response, success=False)
        return DEFAULT_ANALYSIS
        
    except Exception as e:
        logger.error(f"Failed to analyze answer: {e}")
        if response:
            log_ai_response("analysis", response, success=False)
        return DEFAULT_ANALYSIS


def calculate_category_scores(analyses: list[dict]) -> dict:
    """
    –†–∞—Å—Å—á–∏—Ç–∞—Ç—å –∏—Ç–æ–≥–æ–≤—ã–µ –±–∞–ª–ª—ã –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º –Ω–∞ –æ—Å–Ω–æ–≤–µ –≤—Å–µ—Ö –∞–Ω–∞–ª–∏–∑–æ–≤.
    
    12 –º–µ—Ç—Ä–∏–∫ ‚Üí 4 –∫–∞—Ç–µ–≥–æ—Ä–∏–∏:
    - Hard Skills (30): expertise, methodology, tools_proficiency
    - Soft Skills (25): articulation, self_awareness, conflict_handling
    - Thinking (25): depth, structure, systems_thinking, creativity
    - Mindset (20): honesty, growth_orientation
    
    Args:
        analyses: –°–ø–∏—Å–æ–∫ –∞–Ω–∞–ª–∏–∑–æ–≤ –≤—Å–µ—Ö –æ—Ç–≤–µ—Ç–æ–≤
        
    Returns:
        –°–ª–æ–≤–∞—Ä—å —Å –∏—Ç–æ–≥–æ–≤—ã–º–∏ –±–∞–ª–ª–∞–º–∏ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
    """
    if not analyses:
        return {
            "hard_skills": 0,
            "soft_skills": 0,
            "thinking": 0,
            "mindset": 0,
            "total": 0,
        }
    
    # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ –æ—Ü–µ–Ω–∫–∏ –ø–æ 12 –º–µ—Ç—Ä–∏–∫–∞–º
    all_scores = {metric: [] for metric in ALL_METRICS}
    
    for analysis in analyses:
        scores = analysis.get("scores", {})
        for metric in ALL_METRICS:
            if metric in scores:
                all_scores[metric].append(scores[metric])
    
    # –°—Ä–µ–¥–Ω–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è –¥–ª—è –∫–∞–∂–¥–æ–π –º–µ—Ç—Ä–∏–∫–∏
    avg = {k: sum(v) / len(v) if v else 5 for k, v in all_scores.items()}
    
    # === –ú–ê–ü–ü–ò–ù–ì –ù–ê –ö–ê–¢–ï–ì–û–†–ò–ò ===
    
    # Hard Skills (30 –±–∞–ª–ª–æ–≤) = —Å—Ä–µ–¥–Ω–µ–µ –∏–∑ 3 –º–µ—Ç—Ä–∏–∫ √ó 3
    hard_skills_avg = (avg["expertise"] + avg["methodology"] + avg["tools_proficiency"]) / 3
    hard_skills = round(hard_skills_avg * 3)  # 0-10 -> 0-30
    
    # Soft Skills (25 –±–∞–ª–ª–æ–≤) = —Å—Ä–µ–¥–Ω–µ–µ –∏–∑ 3 –º–µ—Ç—Ä–∏–∫ √ó 2.5
    soft_skills_avg = (avg["articulation"] + avg["self_awareness"] + avg["conflict_handling"]) / 3
    soft_skills = round(soft_skills_avg * 2.5)  # 0-10 -> 0-25
    
    # Thinking (25 –±–∞–ª–ª–æ–≤) = —Å—Ä–µ–¥–Ω–µ–µ –∏–∑ 4 –º–µ—Ç—Ä–∏–∫ √ó 2.5
    thinking_avg = (avg["depth"] + avg["structure"] + avg["systems_thinking"] + avg["creativity"]) / 4
    thinking = round(thinking_avg * 2.5)  # 0-10 -> 0-25
    
    # Mindset (20 –±–∞–ª–ª–æ–≤) = —Å—Ä–µ–¥–Ω–µ–µ –∏–∑ 2 –º–µ—Ç—Ä–∏–∫ √ó 2
    mindset_avg = (avg["honesty"] + avg["growth_orientation"]) / 2
    mindset = round(mindset_avg * 2)  # 0-10 -> 0-20
    
    total = hard_skills + soft_skills + thinking + mindset
    
    return {
        "hard_skills": min(hard_skills, 30),
        "soft_skills": min(soft_skills, 25),
        "thinking": min(thinking, 25),
        "mindset": min(mindset, 20),
        "total": min(total, 100),
        "raw_averages": avg,  # –í—Å–µ 12 –º–µ—Ç—Ä–∏–∫ –¥–ª—è –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ –æ—Ç—á—ë—Ç–∞
    }


# –û–∂–∏–¥–∞–µ–º—ã–µ –±–∞–ª–ª—ã –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —É—Ä–æ–≤–Ω—è –æ–ø—ã—Ç–∞
EXPERIENCE_BASELINES = {
    "junior": {
        "expected_total": 35,  # –û–∂–∏–¥–∞–µ–º—ã–π –±–∞–ª–ª –¥–ª—è Junior
        "exceeds_threshold": 50,  # –ï—Å–ª–∏ –≤—ã—à–µ ‚Äî –ø—Ä–µ–≤—ã—à–∞–µ—Ç –æ–∂–∏–¥–∞–Ω–∏—è
        "below_threshold": 25,  # –ï—Å–ª–∏ –Ω–∏–∂–µ ‚Äî –Ω–∏–∂–µ –æ–∂–∏–¥–∞–Ω–∏–π
        "level_name": "Junior",
    },
    "middle": {
        "expected_total": 55,
        "exceeds_threshold": 70,
        "below_threshold": 40,
        "level_name": "Middle",
    },
    "senior": {
        "expected_total": 70,
        "exceeds_threshold": 85,
        "below_threshold": 55,
        "level_name": "Senior",
    },
    "lead": {
        "expected_total": 80,
        "exceeds_threshold": 90,
        "below_threshold": 65,
        "level_name": "Lead",
    },
}


def calibrate_scores(scores: dict, experience: str) -> dict:
    """
    –ö–∞–ª–∏–±—Ä–æ–≤–∞—Ç—å –æ—Ü–µ–Ω–∫–∏ –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ –æ–∂–∏–¥–∞–Ω–∏–π –¥–ª—è —É—Ä–æ–≤–Ω—è –æ–ø—ã—Ç–∞.
    
    Args:
        scores: –°–ª–æ–≤–∞—Ä—å —Å –±–∞–ª–ª–∞–º–∏ –∏–∑ calculate_category_scores()
        experience: –£—Ä–æ–≤–µ–Ω—å –æ–ø—ã—Ç–∞ (junior/middle/senior/lead)
        
    Returns:
        –°–ª–æ–≤–∞—Ä—å —Å –¥–æ–±–∞–≤–ª–µ–Ω–Ω–æ–π –∫–∞–ª–∏–±—Ä–æ–≤–∫–æ–π:
        - expectation: "exceeds" / "meets" / "below"
        - expectation_ru: —Ä—É—Å—Å–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ
        - expected_total: –æ–∂–∏–¥–∞–µ–º—ã–π –±–∞–ª–ª –¥–ª—è —ç—Ç–æ–≥–æ —É—Ä–æ–≤–Ω—è
        - delta: —Ä–∞–∑–Ω–∏—Ü–∞ —Å –æ–∂–∏–¥–∞–Ω–∏–µ–º
        - percentile_in_level: —É—Å–ª–æ–≤–Ω—ã–π –ø–µ—Ä—Ü–µ–Ω—Ç–∏–ª—å –≤–Ω—É—Ç—Ä–∏ —É—Ä–æ–≤–Ω—è
    """
    baseline = EXPERIENCE_BASELINES.get(experience, EXPERIENCE_BASELINES["middle"])
    total = scores.get("total", 0)
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –æ–∂–∏–¥–∞–Ω–∏—è–º
    if total >= baseline["exceeds_threshold"]:
        expectation = "exceeds"
        expectation_ru = "üöÄ –ü—Ä–µ–≤—ã—à–∞–µ—Ç –æ–∂–∏–¥–∞–Ω–∏—è"
        expectation_emoji = "üü¢"
    elif total >= baseline["below_threshold"]:
        expectation = "meets"
        expectation_ru = "‚úÖ –°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç —É—Ä–æ–≤–Ω—é"
        expectation_emoji = "üü°"
    else:
        expectation = "below"
        expectation_ru = "üìà –ï—Å—Ç—å –∑–æ–Ω—ã –¥–ª—è —Ä–æ—Å—Ç–∞"
        expectation_emoji = "üü†"
    
    # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –¥–µ–ª—å—Ç—É –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ –æ–∂–∏–¥–∞–Ω–∏—è
    delta = total - baseline["expected_total"]
    delta_text = f"+{delta}" if delta > 0 else str(delta)
    
    # –£—Å–ª–æ–≤–Ω—ã–π –ø–µ—Ä—Ü–µ–Ω—Ç–∏–ª—å –≤–Ω—É—Ç—Ä–∏ —É—Ä–æ–≤–Ω—è (0-100)
    # –§–æ—Ä–º—É–ª–∞: (total - below) / (exceeds - below) * 100
    range_size = baseline["exceeds_threshold"] - baseline["below_threshold"]
    if range_size > 0:
        percentile = ((total - baseline["below_threshold"]) / range_size) * 100
        percentile = max(0, min(100, percentile))
    else:
        percentile = 50
    
    # –î–æ–±–∞–≤–ª—è–µ–º –∫–∞–ª–∏–±—Ä–æ–≤–∫—É –∫ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–º scores
    calibrated = scores.copy()
    calibrated.update({
        "experience": experience,
        "experience_level": baseline["level_name"],
        "expectation": expectation,
        "expectation_ru": expectation_ru,
        "expectation_emoji": expectation_emoji,
        "expected_total": baseline["expected_total"],
        "delta": delta,
        "delta_text": delta_text,
        "percentile_in_level": round(percentile),
    })
    
    return calibrated

